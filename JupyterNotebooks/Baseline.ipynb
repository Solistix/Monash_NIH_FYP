{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] t_loss: 1.43548 v_loss: 1.17643 val_acc: 0.32444 val_m_acc: 0.32444 f1: 0.00442\n",
      "[2] t_loss: 1.29332 v_loss: 1.19555 val_acc: 0.33333 val_m_acc: 0.33333 f1: -1.00000\n",
      "[3] t_loss: 1.11859 v_loss: 1.19735 val_acc: 0.37667 val_m_acc: 0.37667 f1: -1.00000\n",
      "[4] t_loss: 1.01132 v_loss: 1.24339 val_acc: 0.38222 val_m_acc: 0.38222 f1: -1.00000\n",
      "[5] t_loss: 0.89777 v_loss: 1.24683 val_acc: 0.34556 val_m_acc: 0.34556 f1: -1.00000\n",
      "[6] t_loss: 0.82048 v_loss: 1.26053 val_acc: 0.41333 val_m_acc: 0.41333 f1: -1.00000\n",
      "[7] t_loss: 0.75447 v_loss: 1.27558 val_acc: 0.41667 val_m_acc: 0.41667 f1: -1.00000\n",
      "[8] t_loss: 0.69568 v_loss: 1.25815 val_acc: 0.42778 val_m_acc: 0.42778 f1: -1.00000\n",
      "[9] t_loss: 0.64085 v_loss: 1.27643 val_acc: 0.38333 val_m_acc: 0.38333 f1: 0.11315\n",
      "[10] t_loss: 0.59549 v_loss: 1.20504 val_acc: 0.42111 val_m_acc: 0.42111 f1: 0.16882\n",
      "[11] t_loss: 0.54603 v_loss: 1.20704 val_acc: 0.42222 val_m_acc: 0.42222 f1: 0.15926\n",
      "[12] t_loss: 0.49984 v_loss: 1.21013 val_acc: 0.43667 val_m_acc: 0.43667 f1: 0.17813\n",
      "[13] t_loss: 0.47033 v_loss: 1.17729 val_acc: 0.44778 val_m_acc: 0.44778 f1: 0.17906\n",
      "[14] t_loss: 0.43089 v_loss: 1.19661 val_acc: 0.44333 val_m_acc: 0.44333 f1: 0.16989\n",
      "[15] t_loss: 0.39054 v_loss: 1.18809 val_acc: 0.46333 val_m_acc: 0.46333 f1: 0.18333\n",
      "[16] t_loss: 0.35953 v_loss: 1.22992 val_acc: 0.44778 val_m_acc: 0.44778 f1: 0.17072\n",
      "[17] t_loss: 0.32415 v_loss: 1.17338 val_acc: 0.46444 val_m_acc: 0.46444 f1: 0.17792\n",
      "[18] t_loss: 0.28942 v_loss: 1.22747 val_acc: 0.45778 val_m_acc: 0.45778 f1: 0.17406\n",
      "[19] t_loss: 0.28055 v_loss: 1.18119 val_acc: 0.46556 val_m_acc: 0.46556 f1: 0.18191\n",
      "[20] t_loss: 0.25367 v_loss: 1.21831 val_acc: 0.46111 val_m_acc: 0.46111 f1: 0.17234\n",
      "[21] t_loss: 0.23215 v_loss: 1.19881 val_acc: 0.47000 val_m_acc: 0.47000 f1: 0.18191\n",
      "[22] t_loss: 0.21239 v_loss: 1.25273 val_acc: 0.46222 val_m_acc: 0.46222 f1: 0.17562\n",
      "[23] t_loss: 0.19812 v_loss: 1.21854 val_acc: 0.46778 val_m_acc: 0.46778 f1: 0.18228\n",
      "[24] t_loss: 0.18261 v_loss: 1.24478 val_acc: 0.46556 val_m_acc: 0.46556 f1: 0.17602\n",
      "[25] t_loss: 0.16784 v_loss: 1.29270 val_acc: 0.46333 val_m_acc: 0.46333 f1: 0.17981\n",
      "[26] t_loss: 0.15857 v_loss: 1.23225 val_acc: 0.46778 val_m_acc: 0.46778 f1: 0.17654\n",
      "[27] t_loss: 0.14339 v_loss: 1.24999 val_acc: 0.47667 val_m_acc: 0.47667 f1: 0.17965\n",
      "[28] t_loss: 0.13535 v_loss: 1.25853 val_acc: 0.47778 val_m_acc: 0.47778 f1: 0.18344\n",
      "[29] t_loss: 0.12656 v_loss: 1.30317 val_acc: 0.46556 val_m_acc: 0.46556 f1: 0.17734\n",
      "[30] t_loss: 0.11783 v_loss: 1.28525 val_acc: 0.47111 val_m_acc: 0.47111 f1: 0.18519\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from shared.models import *\n",
    "from shared.datasets import *\n",
    "\n",
    "def train(model, train_loader, criterion, device, optimizer):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for step, (data_inputs, data_labels) in enumerate(train_loader):\n",
    "        inputs, labels = data_inputs.to(device), data_labels.to(device) # Convert Tensors to appropriate device\n",
    "        optimizer.zero_grad() \n",
    "        pred = model(inputs)\n",
    "        loss = criterion(pred, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() # Running training loss\n",
    "        \n",
    "    return train_loss/step\n",
    "\n",
    "def test(model, test_loader, criterion, device, n_way):\n",
    "    model.eval()\n",
    "    true_positive = list(0. for i in range(n_way)) # Number of correctly predicted samples per class\n",
    "    total_truth = list(0. for i in range(n_way)) # Number of ground truths per class\n",
    "    predicted_positive = list(0. for i in range(n_way)) # Number of predicted samples per class\n",
    "    precision = list(0. for i in range(n_way))\n",
    "    recall = list(0. for i in range(n_way))\n",
    "    val_loss = 0\n",
    "    correct_total = 0 # Total correctly predicted samples\n",
    "    total = 0 # Total samples\n",
    "    f1_flag = 0 # Flag for if the model does not predict any positives for a class which breaks precision and F1 score\n",
    "    with torch.no_grad():\n",
    "        for step, (data_inputs, data_labels) in enumerate(test_loader):\n",
    "            inputs, labels = data_inputs.to(device), data_labels.to(device)\n",
    "            pred = model(inputs)\n",
    "            loss = criterion(pred, labels)\n",
    "            val_loss += loss.item() # Running validation loss\n",
    "            _, predicted = torch.max(pred, 1)\n",
    "            correct = (predicted == labels).squeeze() # Samples that are correctly predicted\n",
    "            correct_total += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            \n",
    "            for i in range(len(predicted)):\n",
    "                label = labels[i]\n",
    "                true_positive[label] += correct[i].item() \n",
    "                total_truth[label] += 1\n",
    "                predicted_positive[predicted[i].item()] += 1 # True Positive + False Positive\n",
    "                \n",
    "        # Find class accuracy, precision and recall\n",
    "        for j in range(n_way):\n",
    "            if (predicted_positive[j] == 0 or true_positive[j] == 0):\n",
    "                f1_flag = 1\n",
    "            else:\n",
    "                precision[j] = true_positive[j] / predicted_positive[j]\n",
    "            recall[j] = true_positive[j] / total_truth[j] # Recall is the same as per class accuracy\n",
    "            \n",
    "        # Find Accuracy, Macro Accuracy and Macro F1 Score\n",
    "        macro_acc_sum = 0\n",
    "        f1_sum = 0\n",
    "        for k in range(n_way):\n",
    "            macro_acc_sum += recall[k]\n",
    "            if f1_flag == 0: # Check for broken f1 score\n",
    "                f1_sum = 2 * precision[k] * recall[k] / (precision[k] + recall[k])\n",
    "                \n",
    "        accuracy = correct_total/total\n",
    "        macro_accuracy = macro_acc_sum/n_way \n",
    "        if f1_flag == 0: \n",
    "            f1_score = f1_sum/n_way\n",
    "        else:\n",
    "            f1_score = -1\n",
    "        \n",
    "    return val_loss/step, accuracy, macro_accuracy, f1_score\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    num_epochs = 30\n",
    "    num_workers = 8\n",
    "    bs = 64\n",
    "    n_way = 10\n",
    "    \n",
    "    torch.cuda.set_device(0)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = BaselineNet(n_way).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "    train_dataset = MimicCxrJpg(root='../../../../scratch/rl80/mimic-cxr-jpg-2.0.0.physionet.org/files/',\n",
    "                                csv_path='./splits.csv', mode='base_train', resize=224)\n",
    "    test_dataset = MimicCxrJpg(root='../../../../scratch/rl80/mimic-cxr-jpg-2.0.0.physionet.org/files/',\n",
    "                                csv_path='./splits.csv', mode='base_validate', resize=224)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=bs, shuffle=True, num_workers=num_workers)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=bs, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = train(model, train_loader, criterion, device, optimizer)\n",
    "        val_loss, acc, m_acc, f1 = test(model, test_loader, criterion, device, n_way)\n",
    "\n",
    "        print(f'[{epoch+1}] t_loss: {train_loss:.5f} v_loss: {val_loss:.5f} val_acc: {acc:.5f} val_m_acc: {m_acc:.5f} f1: {f1:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-a6c726f51a75>, line 1)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-a6c726f51a75>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    def train()\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "def train(model, train_loader, criterion, device, optimizer):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for step, (data_inputs, data_labels) in enumerate(train_loader):\n",
    "        inputs, labels = data_inputs.to(device), data_labels.to(device) # Convert Tensors to appropriate device\n",
    "        optimizer.zero_grad() \n",
    "        pred = model(inputs)\n",
    "        loss = criterion(pred, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() # Running training loss\n",
    "        \n",
    "    return train_loss/step\n",
    "\n",
    "def test(model, test_loader, criterion, device, n_way):\n",
    "    model.eval()\n",
    "    true_positive = list(0. for i in range(n_way)) # Number of correctly predicted samples per class\n",
    "    total_truth = list(0. for i in range(n_way)) # Number of ground truths per class\n",
    "    predicted_positive = list(0. for i in range(n_way)) # Number of predicted samples per class\n",
    "    precision = list(0. for i in range(n_way))\n",
    "    recall = list(0. for i in range(n_way))\n",
    "    val_loss = 0\n",
    "    correct_total = 0 # Total correctly predicted samples\n",
    "    total = 0 # Total samples\n",
    "    with torch.no_grad():\n",
    "        for step, (data_inputs, data_labels) in enumerate(test_loader):\n",
    "            inputs, labels = data_inputs.to(device), data_labels.to(device)\n",
    "            pred = model(inputs)\n",
    "            loss = criterion(pred, labels)\n",
    "            val_loss += loss.item() # Running validation loss\n",
    "            _, predicted = torch.max(pred, 1)\n",
    "            correct = (predicted == labels).squeeze() # Samples that are correctly predicted\n",
    "            correct_total += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            \n",
    "            for i in range(len(predicted)):\n",
    "                label = labels[i]\n",
    "                true_positive[label] += correct[i].item() \n",
    "                total_truth[label] += 1\n",
    "                predicted_positive[predicted[i].item()] += 1 # True Positive + False Positive\n",
    "                \n",
    "        # Find class accuracy, precision and recall\n",
    "        for j in range(n_way):\n",
    "            precision[j] = true_positive[j] / predicted_positive[j]\n",
    "            recall[j] = true_positive[j] / total_truth[j] # Recall is the same as per class accuracy\n",
    "            \n",
    "        # Find Accuracy, Macro Accuracy and Macro F1 Score\n",
    "        macro_acc_sum = 0\n",
    "        f1_sum = 0\n",
    "        for k in range(n_way):\n",
    "            macro_acc_sum += recall[k]\n",
    "            f1_sum = 2 * precision[k] * recall[k] / (precision[k] + recall[k])\n",
    "        accuracy = correct_total/total\n",
    "        macro_accuracy = macro_acc_sum/n_way \n",
    "        f1_score = f1_sum/n_way\n",
    "        \n",
    "    return val_loss/step, accuracy, macro_accuracy, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Precision must be int or format string, not '[k]'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/home/ilu3/destinationPath/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m_float_precision_changed\u001b[0;34m(self, name, old, new)\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m                 \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '[k]'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-4c22a41496c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'precision [k]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ilu3/destinationPath/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mmagic\u001b[0;34m(self, arg_s)\u001b[0m\n\u001b[1;32m   2144\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2145\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2146\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2148\u001b[0m     \u001b[0;31m#-------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilu3/destinationPath/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line)\u001b[0m\n\u001b[1;32m   2065\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2066\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2067\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2068\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2069\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-40>\u001b[0m in \u001b[0;36mprecision\u001b[0;34m(self, s)\u001b[0m\n",
      "\u001b[0;32m/home/ilu3/destinationPath/lib/python3.6/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilu3/destinationPath/lib/python3.6/site-packages/IPython/core/magics/basic.py\u001b[0m in \u001b[0;36mprecision\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m    543\u001b[0m         \"\"\"\n\u001b[1;32m    544\u001b[0m         \u001b[0mptformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformatters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text/plain'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m         \u001b[0mptformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat_precision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mptformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat_format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilu3/destinationPath/lib/python3.6/site-packages/traitlets/traitlets.py\u001b[0m in \u001b[0;36m__set__\u001b[0;34m(self, obj, value)\u001b[0m\n\u001b[1;32m    583\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTraitError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The \"%s\" trait is read-only.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilu3/destinationPath/lib/python3.6/site-packages/traitlets/traitlets.py\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, obj, value)\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0;31m# we explicitly compare silent to True just in case the equality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;31m# comparison above returns something other than True/False\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_notify_trait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__set__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilu3/destinationPath/lib/python3.6/site-packages/traitlets/traitlets.py\u001b[0m in \u001b[0;36m_notify_trait\u001b[0;34m(self, name, old_value, new_value)\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0mnew\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m             \u001b[0mowner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m             \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'change'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m         ))\n\u001b[1;32m   1141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilu3/destinationPath/lib/python3.6/site-packages/traitlets/traitlets.py\u001b[0m in \u001b[0;36mnotify_change\u001b[0;34m(self, change)\u001b[0m\n\u001b[1;32m   1174\u001b[0m                 \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m             \u001b[0mc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_add_notifiers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilu3/destinationPath/lib/python3.6/site-packages/traitlets/traitlets.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, change)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchange\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchange\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnargs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchange\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchange\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchange\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnargs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchange\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchange\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchange\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchange\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mowner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilu3/destinationPath/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m_float_precision_changed\u001b[0;34m(self, name, old, new)\u001b[0m\n\u001b[1;32m    616\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Precision must be int or format string, not %r\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"int precision must be non-negative, not %r\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Precision must be int or format string, not '[k]'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "precision[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = {'a': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = (predicted == labels).squeeze()\n",
    "for i in range(len(predicted)):\n",
    "    label = labels[i]\n",
    "    class_correct[label] += correct[i].item()\n",
    "    class_total[label] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'list' and 'list'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-357cdb4ce492>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclass_correct\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mclass_total\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'list' and 'list'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "class_correct / class_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.6666666666666666\n",
      "0.0\n",
      "0.3333333333333333\n",
      "0.0\n",
      "0.2222222222222222\n",
      "0.14285714285714285\n",
      "0.0\n",
      "0.0\n",
      "0.5\n",
      "0.1865079365079365\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for j in range(n_way):\n",
    "    total += class_correct[j] / class_total[j]\n",
    "accuracy = total/n_way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = 0\n",
    "test += 1.5\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False,  True, False, False, False, False, False, False, False, False,\n",
       "        False,  True,  True, False, False, False, False, False, False,  True,\n",
       "        False,  True, False, False,  True, False, False, False,  True, False,\n",
       "        False,  True, False, False, False], device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
