{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "from shared.models import *\n",
    "from shared.new_datasets import *\n",
    "\n",
    "\n",
    "def metrics(true_positive, total_truth, predicted_positive, correct_total, total):\n",
    "    n_way = len(true_positive) # Retrieve n_way from the length of the variables. All 3 inputs should be the same length\n",
    "    f1_flag = 0  # Flag for invalid F1 score\n",
    "    precision = list(0. for i in range(n_way))\n",
    "    recall = list(0. for i in range(n_way))\n",
    "    class_f1 = list(0. for i in range(n_way))\n",
    "    \n",
    "    # Find class accuracy, precision and recall\n",
    "    for j in range(n_way):\n",
    "        if (predicted_positive[j] != 0 and true_positive[j] != 0):  # Check if F1 score is valid\n",
    "            precision[j] = true_positive[j] / predicted_positive[j]\n",
    "            recall[j] = true_positive[j] / total_truth[j]  # Recall is the same as per class accuracy\n",
    "            class_f1[j] = 2 * precision[j] * recall[j] / (precision[j] + recall[j])\n",
    "        else:\n",
    "            f1_flag = 1\n",
    "\n",
    "    # Find Accuracy, Macro Accuracy and Macro F1 Score\n",
    "    macro_acc_sum = 0\n",
    "    f1_sum = 0\n",
    "    for k in range(n_way):\n",
    "        macro_acc_sum += recall[k]\n",
    "        if f1_flag == 0:  # Check for invalid f1 score\n",
    "            f1_sum += class_f1[k]\n",
    "\n",
    "    accuracy = correct_total / total\n",
    "    macro_accuracy = macro_acc_sum / n_way\n",
    "    f1_score = f1_sum / n_way\n",
    "    return accuracy, macro_accuracy, f1_score, class_f1\n",
    "\n",
    "\n",
    "def train(inputs, labels, model, criterion, device, optimizer, freeze=False):\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    \n",
    "    # Freeze all layers except those indicated\n",
    "    if freeze:\n",
    "        for name, param in model.named_parameters():\n",
    "            if name not in freeze:\n",
    "                param.requires_grad = False\n",
    "\n",
    "    # Train the entire support set in one batch\n",
    "    optimizer.zero_grad()\n",
    "    pred = model(inputs)\n",
    "    loss = criterion(pred, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_loss = loss.item()  # Running training loss\n",
    "    \n",
    "    return train_loss\n",
    "    \n",
    "\n",
    "def test(inputs, labels, model, criterion, device, n_way):\n",
    "    # An F1 Score of 0 indicates that it is invalid\n",
    "    model.eval()\n",
    "    true_positive = list(0. for i in range(n_way))  # Number of correctly predicted samples per class\n",
    "    total_truth = list(0. for i in range(n_way))  # Number of ground truths per class\n",
    "    predicted_positive = list(0. for i in range(n_way))  # Number of predicted samples per class\n",
    "    correct_total = 0  # Total correctly predicted samples\n",
    "    total = 0  # Total samples\n",
    "    with torch.no_grad():\n",
    "        # Test the entire query set in one batch\n",
    "        pred = model(inputs)\n",
    "        loss = criterion(pred, labels)\n",
    "        val_loss = loss.item()  # Running validation loss\n",
    "        _, predicted = torch.max(pred, 1)\n",
    "        correct = (predicted == labels).squeeze()  # Samples that are correctly predicted\n",
    "        correct_total += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        for i in range(len(predicted)):\n",
    "            label = labels[i]\n",
    "            true_positive[label] += correct[i].item()\n",
    "            total_truth[label] += 1\n",
    "            predicted_positive[predicted[i].item()] += 1  # True Positive + False Positive\n",
    "            \n",
    "    accuracy, macro_accuracy, f1_score, class_f1 = metrics(true_positive, total_truth,\n",
    "                                                           predicted_positive, correct_total, total)\n",
    "    \n",
    "    return val_loss, accuracy, macro_accuracy, f1_score, class_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34] t_loss: 0.009635225869715214 v_loss: 1.0729824304580688 val_acc: 0.4583333333333333 f1: 0.4527458492975734\n",
      "[22] t_loss: 0.043317437171936035 v_loss: 1.2448405027389526 val_acc: 0.4583333333333333 f1: 0.4568627450980392\n",
      "[15] t_loss: 0.06880378723144531 v_loss: 1.3845996856689453 val_acc: 0.3125 f1: 0.3116883116883117\n",
      "[19] t_loss: 0.03704823553562164 v_loss: 1.2352722883224487 val_acc: 0.4375 f1: 0.43841642228739003\n",
      "[78] t_loss: 0.0025841225869953632 v_loss: 1.6353203058242798 val_acc: 0.4166666666666667 f1: 0.39656352834647396\n"
     ]
    }
   ],
   "source": [
    "#def main():\n",
    "# Set Training Parameters\n",
    "n_way = 3\n",
    "k_shot = 5\n",
    "k_query = 16\n",
    "num_episodes = 5\n",
    "num_epochs = 100\n",
    "num_workers = 12\n",
    "bs = 16\n",
    "lr = 1e-4\n",
    "root = '../../../../scratch/rl80/mimic-cxr-jpg-2.0.0.physionet.org/files'\n",
    "path_splits = '../splits/splits.csv'  # Location of preprocessed splits\n",
    "path_results = '../../results'  # Folder to save the CSV results\n",
    "path_pretrained = '../results/basic/basic_36.pth'\n",
    "freeze = ['linear.weight', 'linear.bias']  # Freeze all layers except linear layers\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Load in data\n",
    "dataset = NovelMimicCxrJpg(root, path_splits, n_way, k_shot, k_query, num_episodes)\n",
    "loader = DataLoader(dataset, batch_size=bs, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "# Create Dataframe to export results to CSV\n",
    "df_results = pd.DataFrame(columns=['Epoch', 'Training Loss', 'Validation Loss', 'Accuracy', 'Macro Accuracy',\n",
    "                                   'Macro-F1 Score'] + [str(x) + ' F1' for x in range(n_way)])\n",
    "\n",
    "# Iterate through batched episodes. One episode is one experiment\n",
    "for step, (support_imgs, support_labels, query_imgs, query_labels) in enumerate(loader):\n",
    "    # Convert Tensors to appropriate device\n",
    "    batch_support_x, batch_support_y = support_imgs.to(device), support_labels.to(device)\n",
    "    batch_query_x, batch_query_y = query_imgs.to(device), query_labels.to(device)\n",
    "\n",
    "    # [num_batch, training_sz, channels, height, width] = support_x.size()\n",
    "    # num_batch = num of episodes\n",
    "    # training_sz = size of support or query set\n",
    "    num_batch = batch_support_x.size(0) # Number of episodes in the batch\n",
    "    \n",
    "    # Break down the batch of episodes into single episodes\n",
    "    for i in range(num_batch):\n",
    "        # Load in model and reset weights every episode/experiment\n",
    "        model = BaselineNet(n_way).to(device)\n",
    "        pretrained_dict = torch.load(path_pretrained)\n",
    "        del pretrained_dict['linear.weight']  # Remove the last linear layer\n",
    "        del pretrained_dict['linear.bias']\n",
    "        model_dict = model.state_dict()\n",
    "        model_dict.update(pretrained_dict)\n",
    "        model.load_state_dict(model_dict)\n",
    "        \n",
    "        # Reset optimizer with model parameters\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        \n",
    "        # Break down the sets into individual episodes\n",
    "        support_x, support_y = batch_support_x[i], batch_support_y[i]\n",
    "        query_x, query_y = batch_query_x[i], batch_query_y[i]\n",
    "\n",
    "        # Variables for best epoch per experiment\n",
    "        best_score = 0\n",
    "        best_epoch = 0\n",
    "        df_best = pd.DataFrame(columns=['Epoch', 'Training Loss', 'Validation Loss', 'Accuracy', 'Macro Accuracy',\n",
    "                                   'Macro-F1 Score'] + [str(x) + ' F1' for x in range(n_way)]) # Track best epoch\n",
    "        # Training and testing for specified epochs\n",
    "        for epoch in range(num_epochs):\n",
    "            # Training\n",
    "            train_loss = train(support_x, support_y, model, criterion, device, optimizer, freeze=freeze)\n",
    "\n",
    "            # Testing\n",
    "            val_loss, acc, m_acc, macro_f1, class_f1 = test(query_x, query_y, model, criterion, device, n_way)\n",
    "            \n",
    "            # Find best epoch\n",
    "            score = 0.5*acc + 0.5*macro_f1\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_epoch = epoch + 1\n",
    "                df_best.loc[0] = [epoch + 1, train_loss, val_loss, acc, m_acc, macro_f1] + class_f1\n",
    "                \n",
    "            #print(\n",
    "            #    f'[{epoch + 1}] t_loss: {train_loss:.5f} v_loss: {val_loss:.5f} val_acc: {acc:.5f} '\n",
    "            #    f'val_m_acc: {m_acc:.5f} f1: {macro_f1:.5f}')\n",
    "        \n",
    "        # Print the best results per experiment\n",
    "        print(\n",
    "            f'[{int(df_best.iloc[0,0])}] t_loss: {df_best.iloc[0,1]} v_loss: {df_best.iloc[0,2]} '\n",
    "            f'val_acc: {df_best.iloc[0,3]} f1: {df_best.iloc[0,5]}')\n",
    "    \n",
    "        # Record the best epoch to be saved into a CSV\n",
    "        df_results = df_results.append(df_best.loc[0], ignore_index=True)\n",
    "        \n",
    "# Create results folder if it does not exist\n",
    "if not os.path.exists(path_results):\n",
    "    os.makedirs(path_results)\n",
    "    \n",
    "# Export results to a CSV file\n",
    "df_results.to_csv(os.path.join(path_results, f'{k_shot}shot_baseline.csv'), index=False)\n",
    "\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "#    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 4])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [3, 2, 2, 3, 4, 4, 4, 2, 4, 2, 3, 3, 2, 4, 3]\n",
    "new_labels = labels\n",
    "unique_labels = np.unique(labels)\n",
    "unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro Accuracy</th>\n",
       "      <th>Macro-F1 Score</th>\n",
       "      <th>0 F1</th>\n",
       "      <th>1 F1</th>\n",
       "      <th>2 F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0.050457</td>\n",
       "      <td>1.249611</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.464103</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Epoch  Training Loss  Validation Loss  Accuracy  Macro Accuracy  \\\n",
       "0   21.0       0.050457         1.249611  0.520833        0.520833   \n",
       "\n",
       "   Macro-F1 Score  0 F1  1 F1      2 F1  \n",
       "0        0.464103   0.6   0.1  0.692308  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro Accuracy</th>\n",
       "      <th>Macro-F1 Score</th>\n",
       "      <th>0 F1</th>\n",
       "      <th>1 F1</th>\n",
       "      <th>2 F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0.050457</td>\n",
       "      <td>1.249611</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.464103</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0.050457</td>\n",
       "      <td>1.249611</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.464103</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0.050457</td>\n",
       "      <td>1.249611</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.464103</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0.050457</td>\n",
       "      <td>1.249611</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.464103</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0.050457</td>\n",
       "      <td>1.249611</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.464103</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0.050457</td>\n",
       "      <td>1.249611</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.464103</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0.050457</td>\n",
       "      <td>1.249611</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.464103</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0.050457</td>\n",
       "      <td>1.249611</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.464103</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Epoch  Training Loss  Validation Loss  Accuracy  Macro Accuracy  \\\n",
       "0   21.0       0.050457         1.249611  0.520833        0.520833   \n",
       "1   21.0       0.050457         1.249611  0.520833        0.520833   \n",
       "2   21.0       0.050457         1.249611  0.520833        0.520833   \n",
       "3   21.0       0.050457         1.249611  0.520833        0.520833   \n",
       "4   21.0       0.050457         1.249611  0.520833        0.520833   \n",
       "5   21.0       0.050457         1.249611  0.520833        0.520833   \n",
       "6   21.0       0.050457         1.249611  0.520833        0.520833   \n",
       "7   21.0       0.050457         1.249611  0.520833        0.520833   \n",
       "\n",
       "   Macro-F1 Score  0 F1  1 F1      2 F1  \n",
       "0        0.464103   0.6   0.1  0.692308  \n",
       "1        0.464103   0.6   0.1  0.692308  \n",
       "2        0.464103   0.6   0.1  0.692308  \n",
       "3        0.464103   0.6   0.1  0.692308  \n",
       "4        0.464103   0.6   0.1  0.692308  \n",
       "5        0.464103   0.6   0.1  0.692308  \n",
       "6        0.464103   0.6   0.1  0.692308  \n",
       "7        0.464103   0.6   0.1  0.692308  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test/test'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join('test','test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5 = [x for x, label in enumerate(labels) if label == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
