{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 7.43 GiB total capacity; 6.80 GiB already allocated; 23.12 MiB free; 6.80 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6d0e310fabe7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;31m#print(f'MAML Training {sys.argv[1]} shot')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;31m#main(int(sys.argv[1])) # Get the k_shot variable from command line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-6d0e310fabe7>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(k_shot)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mx_spt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_spt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_qry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_qry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_spt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_spt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_qry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_qry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0maccs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_spt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_spt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_qry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_qry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilu3/destinationPath/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projects/rl80/Monash_NIH_FYP/shared/meta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x_spt, y_spt, x_qry, y_qry)\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m                 \u001b[0;31m# 1. run the i-th task and compute loss for k=1~K-1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_spt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfast_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbn_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_spt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0;31m# 2. compute grad on theta_pi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilu3/destinationPath/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projects/rl80/Monash_NIH_FYP/shared/meta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, vars, bn_training)\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsample_nearest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;34m'max_pool2d'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;34m'avg_pool2d'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilu3/destinationPath/lib/python3.6/site-packages/torch/_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilu3/destinationPath/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_max_pool2d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    574\u001b[0m         \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m     return torch.max_pool2d(\n\u001b[0;32m--> 576\u001b[0;31m         input, kernel_size, stride, padding, dilation, ceil_mode)\n\u001b[0m\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m max_pool2d = boolean_dispatch(\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 7.43 GiB total capacity; 6.80 GiB already allocated; 23.12 MiB free; 6.80 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "import  torch, os\n",
    "import  pandas as pd\n",
    "import  numpy as np\n",
    "import  scipy.stats\n",
    "from    torch.utils.data import DataLoader\n",
    "import  sys\n",
    "\n",
    "sys.path.append('..')\n",
    "from shared.datasets import *\n",
    "from shared.meta import *\n",
    "\n",
    "\n",
    "def main(k_shot):\n",
    "    n_way = 3\n",
    "    k_query = 16\n",
    "    num_workers = 12\n",
    "    train_num_episodes = 5\n",
    "    test_num_episodes = 5\n",
    "    bs = 1\n",
    "    root = '../../../../scratch/rl80/mimic-cxr-jpg-2.0.0.physionet.org/files'\n",
    "    path_splits = '../splits/splits.csv'  # Location of preprocessed splits\n",
    "    path_results = '../../results'  # Folder to save the CSV results\n",
    "\n",
    "    update_lr = 1e-2 # Learning rate for meta-training\n",
    "    meta_lr = 1e-3 # Learning rate for meta-testing\n",
    "    update_step = 5 # Number of meta-training update steps\n",
    "    update_step_test = 10 # Number of meta-testing update steps\n",
    "    imgsz = 224 # Size of images\n",
    "    imgc = 1 # Initial image channels\n",
    "\n",
    "    # Learner model configuration\n",
    "    config = [\n",
    "        ('conv2d', [64, 1, 3, 3, 1, 1]),\n",
    "        ('relu', [True]),\n",
    "        ('bn', [64]),\n",
    "        ('max_pool2d', [2, 2, 0]),\n",
    "        ('conv2d', [64, 64, 3, 3, 1, 1]),\n",
    "        ('relu', [True]),\n",
    "        ('bn', [64]),\n",
    "        ('max_pool2d', [2, 2, 0]),\n",
    "        ('conv2d', [64, 64, 3, 3, 1, 1]),\n",
    "        ('relu', [True]),\n",
    "        ('bn', [64]),\n",
    "        ('max_pool2d', [2, 2, 0]),\n",
    "        ('conv2d', [64, 64, 3, 3, 1, 1]),\n",
    "        ('relu', [True]),\n",
    "        ('bn', [64]),\n",
    "        ('max_pool2d', [2, 2, 0]),\n",
    "        ('flatten', []),\n",
    "        ('linear', [n_way, 64 * 14 * 14])\n",
    "    ]\n",
    "\n",
    "    torch.cuda.set_device(0)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    maml = Meta(update_lr, meta_lr, n_way, k_shot, k_query, bs,\n",
    "                update_step, update_step_test, imgc, imgsz, config).to(device)\n",
    "    tmp = filter(lambda x: x.requires_grad, maml.parameters())\n",
    "    num = sum(map(lambda x: np.prod(x.shape), tmp))\n",
    "    \n",
    "    # Create batched episode datasets\n",
    "    mini = MimicCxrJpgEpisodes(root, path_splits, n_way, k_shot, k_query, train_num_episodes, mode=\"base\")\n",
    "    mini_test = MimicCxrJpgEpisodes(root, path_splits, n_way, k_shot, k_query, test_num_episodes, mode=\"novel\")\n",
    "\n",
    "    # fetch meta_batchsz num of episode each time\n",
    "    db = DataLoader(mini, batch_size=bs, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "    # Keep track of best meta-testing results\n",
    "    best_score = 0\n",
    "    best_step = 0\n",
    "\n",
    "    for step, (x_spt, y_spt, x_qry, y_qry) in enumerate(db):\n",
    "\n",
    "        x_spt, y_spt, x_qry, y_qry = x_spt.to(device), y_spt.to(device), x_qry.to(device), y_qry.to(device)\n",
    "\n",
    "        accs = maml(x_spt, y_spt, x_qry, y_qry)\n",
    "\n",
    "        if (step+1) % 5 == 0:  # evaluation\n",
    "            # Create Dataframe containing results of the multiple episodes\n",
    "            df_results = pd.DataFrame(columns=['Step', 'Accuracy', 'Macro Accuracy',\n",
    "                                               'Macro-F1 Score'] + [str(x) + ' F1' for x in range(n_way)])\n",
    "            db_test = DataLoader(mini_test, 1, shuffle=True, num_workers=1, pin_memory=True)\n",
    "            accs_all_test = []\n",
    "\n",
    "            for x_spt, y_spt, x_qry, y_qry in db_test:\n",
    "                x_spt, y_spt = x_spt.squeeze(0).to(device), y_spt.squeeze(0).to(device)\n",
    "                x_qry, y_qry = x_qry.squeeze(0).to(device), y_qry.squeeze(0).to(device)\n",
    "\n",
    "                # Record the best step per episode\n",
    "                df_best = maml.finetunning(x_spt, y_spt, x_qry, y_qry)\n",
    "                df_results = df_results.append(df_best.loc[0], ignore_index=True)\n",
    "\n",
    "            \n",
    "\n",
    "            # Find average accuracy and average f1 score over the experiments\n",
    "            average_accuracy = df_results[\"Accuracy\"].mean()\n",
    "            average_f1 = df_results[\"Macro-F1 Score\"].mean()\n",
    "            print(f'Step: {step} Accuracy: {average_accuracy} F1-Score: {average_f1}') # Print results\n",
    "\n",
    "            # Record best testing results\n",
    "            score = 0.5*average_accuracy + 0.5*average_f1\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_step = step\n",
    "                df_best_test = df_results\n",
    "\n",
    "    print(f\"Best Step: {best_step}\")\n",
    "\n",
    "    # Create results folder if it does not exist\n",
    "    if not os.path.exists(path_results):\n",
    "        os.makedirs(path_results)\n",
    "\n",
    "    df_best_test.to_csv(os.path.join(path_results, f'{k_shot}shot_MAML_{best_step}.csv'), index=False)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #print(f'MAML Training {sys.argv[1]} shot')\n",
    "    #main(int(sys.argv[1])) # Get the k_shot variable from command line\n",
    "    main(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
